{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eegcpc.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADMoreau/EEG_CPC/blob/master/eegcpc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpjIjArH3GZJ",
        "colab_type": "code",
        "outputId": "b7d1106b-4dd1-4dbf-dc25-ea66b092746a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmmRB_MgBqg0",
        "colab_type": "code",
        "outputId": "a8aa4486-ec7f-4397-9f66-54ad9ba80af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        }
      },
      "source": [
        "!pip install braindecode\n",
        "!pip install mne\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mne\n",
        "import logging\n",
        "import os.path\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from braindecode.models.deep4 import Deep4Net\n",
        "from braindecode.datasets.bcic_iv_2a import BCICompetition4Set2A\n",
        "from braindecode.experiments.experiment import Experiment\n",
        "from braindecode.experiments.monitors import (\n",
        "    LossMonitor,\n",
        "    MisclassMonitor,\n",
        "    RuntimeMonitor,\n",
        ")\n",
        "from braindecode.experiments.stopcriteria import MaxEpochs, NoDecrease, Or\n",
        "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
        "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
        "from braindecode.datautil.splitters import split_into_two_sets\n",
        "from braindecode.torch_ext.constraints import MaxNormDefaultConstraint\n",
        "from braindecode.torch_ext.util import set_random_seeds, np_to_var\n",
        "from braindecode.mne_ext.signalproc import mne_apply, resample_cnt\n",
        "from braindecode.datautil.signalproc import (\n",
        "    highpass_cnt,\n",
        "    bandpass_cnt,\n",
        "    exponential_running_standardize,\n",
        ")\n",
        "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting braindecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/4d/712664444016ba0dd369d7f8ca36448f4c92f7a114e296d9cd40eed67b23/Braindecode-0.4.85.tar.gz (324kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 20.9MB/s \n",
            "\u001b[?25hCollecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/7c/ad1b52a3fdd4be8f55e183f1eff7d76f48cd1bee83c5630f9c26770e032e/mne-0.19.2-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from braindecode) (1.17.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from braindecode) (0.25.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from braindecode) (1.4.1)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.6/dist-packages (from braindecode) (0.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from braindecode) (3.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from braindecode) (2.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->braindecode) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->braindecode) (2018.9)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from resampy->braindecode) (1.12.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy->braindecode) (0.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->braindecode) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->braindecode) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->braindecode) (0.10.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy->braindecode) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy->braindecode) (45.1.0)\n",
            "Building wheels for collected packages: braindecode\n",
            "  Building wheel for braindecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for braindecode: filename=Braindecode-0.4.85-cp36-none-any.whl size=71078 sha256=69a0eaf62ae4d495b249f1316b0a932c61bc66e4216a31f4bbe5165ceccf9458\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/07/db/c243929cde1ab13cdb3da732b19244e93ed2c44a30894b8c4a\n",
            "Successfully built braindecode\n",
            "Installing collected packages: mne, braindecode\n",
            "Successfully installed braindecode-0.4.85 mne-0.19.2\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.19.2)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZU2B32VB8uk",
        "colab_type": "code",
        "outputId": "ecfeb45e-1379-4a68-8fd9-53b82732f6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from braindecode.datasets.bbci import  BBCIDataset\n",
        "test_cnt = BBCIDataset(filename=\"/content/drive/My Drive/eeg/high-gamma-dataset/data/test/1.mat\").load()\n",
        "train_cnt = BBCIDataset(filename=\"/content/drive/My Drive/eeg/high-gamma-dataset/data/train/1.mat\").load()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating RawArray with float64 data, n_channels=128, n_times=616535\n",
            "    Range : 0 ... 616534 =      0.000 ...  1233.068 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=128, n_times=1225545\n",
            "    Range : 0 ... 1225544 =      0.000 ...  2451.088 secs\n",
            "Ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7RAylq-MFO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "marker_def = OrderedDict([('Right Hand', [1]), ('Left Hand', [2],),\n",
        "                              ('Rest', [3]), ('Feet', [4])])\n",
        "clean_ival = [0, 4000]\n",
        "train_set_for_cleaning = create_signal_target_from_raw_mne(train_cnt, marker_def,\n",
        "                                                  clean_ival)\n",
        "train_clean_trial_mask = np.max(np.abs(train_set_for_cleaning.X), axis=(1, 2)) < 800\n",
        "test_set_for_cleaning = create_signal_target_from_raw_mne(test_cnt, marker_def,\n",
        "                                                  clean_ival)\n",
        "test_clean_trial_mask = np.max(np.abs(test_set_for_cleaning.X), axis=(1, 2)) < 800"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IttkfCr6NNc7",
        "colab_type": "code",
        "outputId": "7fb5f04e-cafb-4432-b5fc-adaa0ac25e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Clean trials: {:3d}  of {:3d} ({:5.1f}%)\".format(\n",
        "        np.sum(train_clean_trial_mask),\n",
        "        len(train_set_for_cleaning.X),\n",
        "        np.mean(train_clean_trial_mask) * 100))\n",
        "print(\"Clean trials: {:3d}  of {:3d} ({:5.1f}%)\".format(\n",
        "        np.sum(test_clean_trial_mask),\n",
        "        len(test_set_for_cleaning.X),\n",
        "        np.mean(test_clean_trial_mask) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clean trials: 319  of 320 ( 99.7%)\n",
            "Clean trials: 160  of 160 (100.0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLLs-QpuNA6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now pick only sensors with C in their name\n",
        "# as they cover motor cortex\n",
        "C_sensors = ['FC5', 'FC1', 'FC2', 'FC6', 'C3', 'C4', 'CP5',\n",
        "              'CP1', 'CP2', 'CP6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2',\n",
        "              'C6',\n",
        "              'CP3', 'CPz', 'CP4', 'FFC5h', 'FFC3h', 'FFC4h', 'FFC6h',\n",
        "              'FCC5h',\n",
        "              'FCC3h', 'FCC4h', 'FCC6h', 'CCP5h', 'CCP3h', 'CCP4h', 'CCP6h',\n",
        "              'CPP5h',\n",
        "              'CPP3h', 'CPP4h', 'CPP6h', 'FFC1h', 'FFC2h', 'FCC1h', 'FCC2h',\n",
        "              'CCP1h',\n",
        "              'CCP2h', 'CPP1h', 'CPP2h']\n",
        "train_cnt = train_cnt.pick_channels(C_sensors)\n",
        "test_cnt = test_cnt.pick_channels(C_sensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfogZZp6NoZY",
        "colab_type": "code",
        "outputId": "4890aff2-1a10-4fdf-c45e-9269870085dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "low_cut_hz = 4\n",
        "train_cnt = resample_cnt(train_cnt, 250.0)\n",
        "train_cnt = mne_apply(\n",
        "    lambda a: highpass_cnt(\n",
        "        a, low_cut_hz, train_cnt.info['sfreq'], filt_order=3, axis=1),\n",
        "    train_cnt)\n",
        "\n",
        "test_cnt = resample_cnt(test_cnt, 250.0)\n",
        "test_cnt = mne_apply(\n",
        "    lambda a: highpass_cnt(\n",
        "        a, low_cut_hz, test_cnt.info['sfreq'], filt_order=3, axis=1),\n",
        "    test_cnt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is not causal, uses future data....\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating RawArray with float64 data, n_channels=44, n_times=612772\n",
            "    Range : 0 ... 612771 =      0.000 ...  2451.084 secs\n",
            "Ready.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "This is not causal, uses future data....\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating RawArray with float64 data, n_channels=44, n_times=308267\n",
            "    Range : 0 ... 308266 =      0.000 ...  1233.064 secs\n",
            "Ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCPZJxFIPEMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trial interval, start at -500 already, since improved decoding for networks\n",
        "ival = [-500, 4000]\n",
        "\n",
        "train_dataset = create_signal_target_from_raw_mne(train_cnt, marker_def, ival)\n",
        "train_dataset.X = train_dataset.X[train_clean_trial_mask]\n",
        "train_dataset.y = train_dataset.y[train_clean_trial_mask]\n",
        "\n",
        "test_dataset = create_signal_target_from_raw_mne(test_cnt, marker_def, ival)\n",
        "test_dataset.X = test_dataset.X[test_clean_trial_mask]\n",
        "test_dataset.y = test_dataset.y[test_clean_trial_mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sUfMsSIUqpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dataset_fraction = 0.8\n",
        "train_dataset, valid_dataset = split_into_two_sets(train_dataset,\n",
        "                                            valid_dataset_fraction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSTJbgVVQB5W",
        "colab_type": "code",
        "outputId": "b52bc5d0-46b3-4101-d944-eee7866e0611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset.X.shape, train_dataset.y.shape, valid_dataset.X.shape, valid_dataset.y.shape, test_dataset.X.shape, test_dataset.y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((255, 44, 1125), (255,), (64, 44, 1125), (64,), (160, 44, 1125), (160,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o999ygdhdXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hby-uclwZU_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Expression(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Compute given expression on forward pass.\n",
        "    Parameters\n",
        "    ----------\n",
        "    expression_fn: function\n",
        "        Should accept variable number of objects of type\n",
        "        `torch.autograd.Variable` to compute its output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, expression_fn):\n",
        "        super(Expression, self).__init__()\n",
        "        self.expression_fn = expression_fn\n",
        "\n",
        "    def forward(self, *x):\n",
        "        return self.expression_fn(*x)\n",
        "\n",
        "    def __repr__(self):\n",
        "        if hasattr(self.expression_fn, \"func\") and hasattr(\n",
        "            self.expression_fn, \"kwargs\"\n",
        "        ):\n",
        "            expression_str = \"{:s} {:s}\".format(\n",
        "                self.expression_fn.func.__name__, str(self.expression_fn.kwargs)\n",
        "            )\n",
        "        elif hasattr(self.expression_fn, \"__name__\"):\n",
        "            expression_str = self.expression_fn.__name__\n",
        "        else:\n",
        "            expression_str = repr(self.expression_fn)\n",
        "        return (\n",
        "            self.__class__.__name__\n",
        "            + \"(\"\n",
        "            + \"expression=\"\n",
        "            + str(expression_str)\n",
        "            + \")\"\n",
        "        )\n",
        "\n",
        "def identity(x):\n",
        "  return x\n",
        "\n",
        "def dot_norm_exp(a,b):\n",
        "  dot = torch.sum(a * b, dim=1)\n",
        "  aa = torch.sum((a**2),dim=1)**0.5\n",
        "  bb = torch.sum((b**2),dim=1)**0.5\n",
        "  dot_norm = dot/(aa*bb)\n",
        "  ret = torch.exp(dot_norm)\n",
        "  return ret\n",
        "\n",
        "def dot_norm(a,b):\n",
        "  dot = torch.sum(a * b, dim=1)\n",
        "  aa = torch.sum((a**2),dim=1)**0.5\n",
        "  bb = torch.sum((b**2),dim=1)**0.5\n",
        "  dot_norm = dot/(aa*bb)\n",
        "  return dot_norm\n",
        "\n",
        "def dot(a,b):\n",
        "  dot = torch.sum(a * b, dim=1)\n",
        "  return dot\n",
        "\n",
        "def norm_euclidean(a,b):\n",
        "  aa = (torch.sum((a**2),dim=1)**0.5).unsqueeze(dim=1)\n",
        "  bb = (torch.sum((b**2),dim=1)**0.5).unsqueeze(dim=1)\n",
        "  return (torch.sum(((a/aa-b/bb)**2),dim=1)**0.5)\n",
        "\n",
        "class channel_encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(channel_encoder, self).__init__()\n",
        "    self.channel_encoder = nn.Sequential(\n",
        "        nn.Conv1d(in_channels = 1,\n",
        "                  out_channels = 25,\n",
        "                  kernel_size = 10,\n",
        "                  stride=1,\n",
        "                  bias=False),\n",
        "        nn.BatchNorm1d(25, momentum=.1, affine=True),\n",
        "        nn.ELU(),\n",
        "        nn.MaxPool1d(kernel_size=3, stride=3),\n",
        "        Expression(identity),\n",
        "        nn.Dropout(p=.5)\n",
        "    )\n",
        "  def forward(self, signal):\n",
        "    return self.channel_encoder(signal)\n",
        "\n",
        "class encoder(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super(encoder, self).__init__()\n",
        "    self.encoders = nn.ModuleList([channel_encoder() for i in range(channels)])\n",
        "    #LSTMs to focus on all the channels at a single time step\n",
        "    self.channels_lstms = nn.ModuleList([nn.LSTM(25, 25, num_layers=1, bidirectional=False, batch_first=True) for i in range(channels)])\n",
        "    #LSTMs to foucs on all previous samples for a single channel\n",
        "    self.samples_lstms = nn.ModuleList([nn.LSTM(25, 25, num_layers=1, bidirectional=False, batch_first=True) for i in range(channels)])    \n",
        "    self.prediction_weights = nn.ModuleList([nn.ModuleList([nn.Linear(in_features=1800,\n",
        "                                                                      out_features=25) \n",
        "                                                            for i in range(13)])\n",
        "                                                            for j in range(channels)])\n",
        "            \n",
        "  def forward(self, input_data):\n",
        "    #input shape = [Batch_size, 44(height), 1125 (width)]\n",
        "    batch_size = input_data.shape[0]\n",
        "    channels = input_data.shape[1]\n",
        "    ''' find the number of windows\n",
        "    windows = 0\n",
        "    # window size = 225, overlap = 75\n",
        "    while (75*i) + 225 <= 1125:\n",
        "      windows += 1\n",
        "    '''\n",
        "    windows = 13 \n",
        "    \n",
        "    # get the latents (z) using the encoders, 1 encoder per channel\n",
        "    z_storage = torch.empty((batch_size, channels, windows, 72, 25)).float().cuda()\n",
        "    for channel in range(channels):\n",
        "      for window in range(windows): # 13 is the number of overlapping windows \n",
        "        w = 75*window\n",
        "        encoder_input = input_data[:, channel, w : w + 225]\n",
        "        encoder_input = encoder_input.unsqueeze(dim=1)\n",
        "        z = self.encoders[channel](encoder_input)\n",
        "        z = z.transpose(1,2)\n",
        "        z_storage[:, channel, window, :, :] = z\n",
        "\n",
        "    #linear modality\n",
        "    ######################\n",
        "    z_targets = torch.empty((batch_size, channels, windows, 25)).float().cuda()\n",
        "    for channel in range(channels):\n",
        "      for window in range(windows): \n",
        "        z_pred_in = z_storage[:, channel, window, : , :]\n",
        "        z_pred_in = nn.Flatten(start_dim=1)(z_pred_in)\n",
        "        z_targets[:, channel, window, :] = self.prediction_weights[channel][window].forward(z_pred_in)\n",
        "    ######################\n",
        "    \n",
        "    #Autoregressive modality\n",
        "    ##############################\n",
        "    z_sample_storage = torch.empty((batch_size, channels, windows, 25)).float().cuda()\n",
        "    for channel in range(channels):\n",
        "      for window in range(windows):\n",
        "        # Get the encoder outputs from single channel previous all windows\n",
        "        z_prev_samples = z_targets[:, channel, :window+1, :]\n",
        "        # flatten for lstm\n",
        "        #z_prev_samples = nn.Flatten(start_dim=1, end_dim=3)(z_prev_samples)\n",
        "        z_samples_prev, _ = self.channels_lstms[channel](z_prev_samples)\n",
        "        # get final output sample\n",
        "        z_sample = z_samples_prev[:, -1, :]\n",
        "        z_sample_storage[:, channel, window, :] = z_sample\n",
        "\n",
        "    z_preds = torch.empty((batch_size, channels, windows, 25)).float().cuda()\n",
        "    for channel in range(channels):\n",
        "      for window in range(windows):   \n",
        "        # Get the encoder ouputs from previous time window across all channels \n",
        "        z_prev_channels = z_sample_storage[:, :, window, :]\n",
        "        #flatten for lstm\n",
        "        #z_prev_channels = nn.Flatten(start_dim=1, end_dim=3)(z_prev_channels)\n",
        "        z_channel_prev, _ = self.samples_lstms[channel](z_prev_channels)\n",
        "        z_sample = z_channel_prev[:, -1, :]\n",
        "        z_preds[:, channel, window, :] = z_sample\n",
        "    #############################\n",
        "\n",
        "    # Calculate error\n",
        "    #############################\n",
        "    losses = []\n",
        "    for batch in range(batch_size):\n",
        "      for channel in range(channels):\n",
        "        for window in range(0, windows-2): # skip reading 0/ start at 0\n",
        "          c_i_j = z_preds[batch, channel, window, :].unsqueeze(dim=0)\n",
        "          #for pred_window in range(window+1, windows):\n",
        "          #z_hat = z_targets[batch, channel, pred_window, :].unsqueeze(dim=0)\n",
        "          z_hat = z_targets[batch, channel, window + 2, :].unsqueeze(dim=0)\n",
        "          dot_norm_val = dot_norm_exp(c_i_j, z_hat)\n",
        "          euc_loss_val = norm_euclidean(c_i_j, z_hat)\n",
        "          good_term_dot = dot(c_i_j, z_hat)\n",
        "          dot_terms = [torch.unsqueeze(good_term_dot,dim=0)]\n",
        "\n",
        "          #for rand in range(8):\n",
        "          if batch == 0:\n",
        "            a = np.random.randint(batch_size, size=1)[0]\n",
        "            b = np.random.randint(channels, size=1)[0]\n",
        "            c = np.random.randint(windows, size=1)[0]\n",
        "            bad_term_dot = dot(c_i_j, z_targets[a, b, c, :])\n",
        "            dot_terms.append(torch.unsqueeze(bad_term_dot, dim=0))\n",
        "\n",
        "          log_softmax = torch.log_softmax(torch.cat(dot_terms, dim=0), dim=0)\n",
        "          losses.append(-log_softmax[0,])\n",
        "\n",
        "    #############################\n",
        "    \n",
        "\n",
        "    loss = torch.mean(torch.cat(losses))\n",
        "    loss.backward()\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGS3gJEURI8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(torch.Tensor(train_dataset.X), torch.Tensor(train_dataset.y))\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkcVKgGLeV1G",
        "colab_type": "code",
        "outputId": "7513ddcd-c1e8-4322-8384-8925c19bbfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import sys\n",
        "import time\n",
        "\n",
        "model = encoder(channels = 44).cuda()\n",
        "optimizer = torch.optim.Adam(params = model.parameters())\n",
        "model.train()\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "  batch_loss = 0\n",
        "  now = time.time()\n",
        "  for l, (X, y) in enumerate(loader):\n",
        "    loss = model.forward(X.cuda())\n",
        "    batch_loss += loss.item()\n",
        "    sys.stdout.write('\\rEpoch %d Batch %d Loss %f' % (epoch, l, loss))\n",
        "    sys.stdout.flush()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  batch_loss /= l + 1\n",
        "  then = time.time()\n",
        "  elapsed = then - now\n",
        "  print(f\"\\rEpoch {epoch} Loss {round(batch_loss, 6)} Elapsed Time {round(elapsed, 2)} seconds\")\n",
        "  torch.save(model.state_dict(), os.path.join(\"/content/drive/My Drive/eeg/encoder_weights.pt\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss 0.022699 Elapsed Time 174.76 seconds\n",
            "Epoch 1 Loss 0.013189 Elapsed Time 173.17 seconds\n",
            "Epoch 2 Loss 0.006269 Elapsed Time 169.48 seconds\n",
            "Epoch 3 Loss 0.003913 Elapsed Time 166.07 seconds\n",
            "Epoch 4 Loss 0.002324 Elapsed Time 165.87 seconds\n",
            "Epoch 5 Loss 0.001676 Elapsed Time 165.04 seconds\n",
            "Epoch 6 Loss 0.001443 Elapsed Time 165.28 seconds\n",
            "Epoch 7 Loss 0.001222 Elapsed Time 164.6 seconds\n",
            "Epoch 8 Loss 0.000933 Elapsed Time 165.88 seconds\n",
            "Epoch 9 Loss 0.000653 Elapsed Time 167.17 seconds\n",
            "Epoch 10 Loss 0.000804 Elapsed Time 166.78 seconds\n",
            "Epoch 11 Loss 0.001034 Elapsed Time 165.87 seconds\n",
            "Epoch 12 Loss 0.000789 Elapsed Time 165.36 seconds\n",
            "Epoch 13 Loss 0.000765 Elapsed Time 165.85 seconds\n",
            "Epoch 14 Loss 0.001077 Elapsed Time 163.51 seconds\n",
            "Epoch 15 Loss 0.000622 Elapsed Time 164.07 seconds\n",
            "Epoch 16 Loss 0.001015 Elapsed Time 164.74 seconds\n",
            "Epoch 17 Loss 0.000704 Elapsed Time 164.6 seconds\n",
            "Epoch 18 Loss 0.001352 Elapsed Time 162.87 seconds\n",
            "Epoch 19 Loss 0.000803 Elapsed Time 163.49 seconds\n",
            "Epoch 20 Loss 0.000926 Elapsed Time 164.13 seconds\n",
            "Epoch 21 Loss 0.001628 Elapsed Time 163.83 seconds\n",
            "Epoch 22 Loss 0.000922 Elapsed Time 163.18 seconds\n",
            "Epoch 23 Loss 0.000742 Elapsed Time 161.86 seconds\n",
            "Epoch 24 Loss 0.000637 Elapsed Time 162.79 seconds\n",
            "Epoch 25 Loss 0.000714 Elapsed Time 162.36 seconds\n",
            "Epoch 26 Loss 0.000914 Elapsed Time 162.51 seconds\n",
            "Epoch 27 Loss 0.000901 Elapsed Time 162.65 seconds\n",
            "Epoch 28 Loss 0.001317 Elapsed Time 163.16 seconds\n",
            "Epoch 29 Loss 0.000741 Elapsed Time 162.38 seconds\n",
            "Epoch 30 Loss 0.000572 Elapsed Time 161.6 seconds\n",
            "Epoch 31 Loss 0.001077 Elapsed Time 161.8 seconds\n",
            "Epoch 32 Loss 0.000626 Elapsed Time 161.93 seconds\n",
            "Epoch 33 Loss 0.000904 Elapsed Time 161.83 seconds\n",
            "Epoch 34 Loss 0.00122 Elapsed Time 161.82 seconds\n",
            "Epoch 35 Loss 0.001277 Elapsed Time 162.06 seconds\n",
            "Epoch 36 Loss 0.000727 Elapsed Time 162.09 seconds\n",
            "Epoch 37 Loss 0.000742 Elapsed Time 162.49 seconds\n",
            "Epoch 38 Loss 0.000849 Elapsed Time 161.83 seconds\n",
            "Epoch 39 Loss 0.001013 Elapsed Time 161.66 seconds\n",
            "Epoch 40 Loss 0.000904 Elapsed Time 161.79 seconds\n",
            "Epoch 41 Loss 0.000634 Elapsed Time 161.79 seconds\n",
            "Epoch 42 Loss 0.00096 Elapsed Time 162.71 seconds\n",
            "Epoch 43 Loss 0.000668 Elapsed Time 162.55 seconds\n",
            "Epoch 44 Loss 0.00092 Elapsed Time 169.21 seconds\n",
            "Epoch 45 Loss 0.000613 Elapsed Time 170.27 seconds\n",
            "Epoch 46 Loss 0.000435 Elapsed Time 166.33 seconds\n",
            "Epoch 47 Loss 0.001554 Elapsed Time 165.55 seconds\n",
            "Epoch 48 Loss 0.000581 Elapsed Time 168.29 seconds\n",
            "Epoch 49 Loss 0.000494 Elapsed Time 167.28 seconds\n",
            "Epoch 50 Loss 0.000606 Elapsed Time 166.55 seconds\n",
            "Epoch 51 Loss 0.000589 Elapsed Time 166.81 seconds\n",
            "Epoch 52 Loss 0.00082 Elapsed Time 166.42 seconds\n",
            "Epoch 53 Loss 0.000644 Elapsed Time 168.7 seconds\n",
            "Epoch 54 Loss 0.000677 Elapsed Time 166.38 seconds\n",
            "Epoch 55 Loss 0.000886 Elapsed Time 169.38 seconds\n",
            "Epoch 56 Loss 0.000651 Elapsed Time 169.75 seconds\n",
            "Epoch 57 Loss 0.000641 Elapsed Time 167.62 seconds\n",
            "Epoch 58 Loss 0.000596 Elapsed Time 166.77 seconds\n",
            "Epoch 59 Loss 0.000452 Elapsed Time 165.55 seconds\n",
            "Epoch 60 Loss 0.000556 Elapsed Time 165.6 seconds\n",
            "Epoch 61 Loss 0.000683 Elapsed Time 165.62 seconds\n",
            "Epoch 62 Loss 0.000559 Elapsed Time 164.06 seconds\n",
            "Epoch 63 Loss 0.000398 Elapsed Time 162.21 seconds\n",
            "Epoch 64 Loss 0.000499 Elapsed Time 161.44 seconds\n",
            "Epoch 65 Loss 0.000541 Elapsed Time 161.08 seconds\n",
            "Epoch 66 Loss 0.000582 Elapsed Time 160.91 seconds\n",
            "Epoch 67 Loss 0.000829 Elapsed Time 161.17 seconds\n",
            "Epoch 68 Loss 0.000679 Elapsed Time 161.9 seconds\n",
            "Epoch 69 Loss 0.000906 Elapsed Time 161.44 seconds\n",
            "Epoch 70 Loss 0.000399 Elapsed Time 162.26 seconds\n",
            "Epoch 71 Loss 0.000744 Elapsed Time 161.71 seconds\n",
            "Epoch 72 Loss 0.000629 Elapsed Time 162.4 seconds\n",
            "Epoch 73 Loss 0.000385 Elapsed Time 162.7 seconds\n",
            "Epoch 74 Loss 0.000362 Elapsed Time 163.52 seconds\n",
            "Epoch 75 Loss 0.000503 Elapsed Time 163.36 seconds\n",
            "Epoch 76 Loss 0.000363 Elapsed Time 163.01 seconds\n",
            "Epoch 77 Loss 0.000813 Elapsed Time 162.47 seconds\n",
            "Epoch 78 Loss 0.000451 Elapsed Time 161.56 seconds\n",
            "Epoch 79 Loss 0.00076 Elapsed Time 162.26 seconds\n",
            "Epoch 80 Loss 0.000742 Elapsed Time 162.28 seconds\n",
            "Epoch 81 Loss 0.000518 Elapsed Time 162.63 seconds\n",
            "Epoch 82 Loss 0.000404 Elapsed Time 163.08 seconds\n",
            "Epoch 83 Loss 0.000287 Elapsed Time 162.98 seconds\n",
            "Epoch 84 Loss 0.000457 Elapsed Time 161.91 seconds\n",
            "Epoch 85 Loss 0.000608 Elapsed Time 162.36 seconds\n",
            "Epoch 86 Loss 0.000742 Elapsed Time 163.39 seconds\n",
            "Epoch 87 Loss 0.000605 Elapsed Time 162.73 seconds\n",
            "Epoch 88 Loss 0.000567 Elapsed Time 162.02 seconds\n",
            "Epoch 89 Loss 0.000386 Elapsed Time 162.36 seconds\n",
            "Epoch 90 Loss 0.000321 Elapsed Time 162.16 seconds\n",
            "Epoch 91 Loss 0.000476 Elapsed Time 162.27 seconds\n",
            "Epoch 92 Loss 0.000411 Elapsed Time 162.1 seconds\n",
            "Epoch 93 Loss 0.000548 Elapsed Time 162.25 seconds\n",
            "Epoch 94 Loss 0.000451 Elapsed Time 161.82 seconds\n",
            "Epoch 95 Loss 0.00049 Elapsed Time 161.6 seconds\n",
            "Epoch 96 Loss 0.000427 Elapsed Time 161.61 seconds\n",
            "Epoch 97 Loss 0.000323 Elapsed Time 161.29 seconds\n",
            "Epoch 98 Loss 0.001031 Elapsed Time 161.72 seconds\n",
            "Epoch 99 Loss 0.000382 Elapsed Time 161.28 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svDJTBZ15I3H",
        "colab_type": "code",
        "outputId": "8c4ead15-7644-480d-e54d-c017356c287c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test = torch.Tensor(train_set.X[0, 0, :225]).unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "print(test.shape)\n",
        "model = encoder(channels = 44)\n",
        "out = model.forward(torch.Tensor(train_set.X[0, :, :]).unsqueeze(dim=0))\n",
        "out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 225])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8942, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2oFPhohav-K",
        "colab_type": "code",
        "outputId": "f37ee439-1b2e-4c10-9b71-45867a12eeee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rnn = nn.GRU(10, 20, 2)\n",
        "input = torch.randn(5, 3, 10)\n",
        "h0 = torch.randn(2, 3, 20)\n",
        "output, hn = rnn(input, h0)\n",
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y400La7g2i9m",
        "colab_type": "code",
        "outputId": "9b338818-60fe-4dca-d3a7-14563961531e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rnn = nn.LSTM(10, 100, 2)\n",
        "input = torch.randn(5, 300, 10)\n",
        "h0 = torch.randn(2, 3, 100)\n",
        "c0 = torch.randn(2, 3, 100)\n",
        "output, (hn, cn) = rnn(input)\n",
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 300, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckjgY2ij20bH",
        "colab_type": "code",
        "outputId": "b4862af0-fc4f-4ea4-a315-6ce918f6a7f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "import numpy as np\n",
        "arr = np.ones((1, 1125))\n",
        "i = 0\n",
        "while (75*i) + 225 <= 1125:\n",
        "  i += 1\n",
        "print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 225\n",
            "(1, 225)\n",
            "75 300\n",
            "(1, 225)\n",
            "150 375\n",
            "(1, 225)\n",
            "225 450\n",
            "(1, 225)\n",
            "300 525\n",
            "(1, 225)\n",
            "375 600\n",
            "(1, 225)\n",
            "450 675\n",
            "(1, 225)\n",
            "525 750\n",
            "(1, 225)\n",
            "600 825\n",
            "(1, 225)\n",
            "675 900\n",
            "(1, 225)\n",
            "750 975\n",
            "(1, 225)\n",
            "825 1050\n",
            "(1, 225)\n",
            "900 1125\n",
            "(1, 225)\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}